{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BCF9LgbNc5c",
        "outputId": "8cce78e7-f3c3-4848-d9b9-cf838f3fac6b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "ErWklv7OMvNC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjIHPIWAMsJU",
        "outputId": "2928ba02-096b-4cb1-b723-8f39278e32b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your query (or type 'exit'): how are you\n",
            "\n",
            "Response:\n",
            " I'm doing great, thank you for asking. It's lovely to chat with you. How about you? Is there anything on your mind that you'd like to talk about or perhaps you have a question? I'm here to help.\n",
            "\n",
            "Enter your query (or type 'exit'): I was charged twice for my subscription this month.\n",
            "\n",
            "Response:\n",
            " I'm so sorry to hear that you've been charged twice for your subscription. I'm here to help you resolve this issue as quickly as possible.\n",
            "\n",
            "To assist you further, could you please provide me with some information? \n",
            "\n",
            "1. Can you confirm the dates when you were charged for your subscription?\n",
            "2. Are you using a credit card or another payment method?\n",
            "3. Can you check your account and provide me with the exact amounts you were charged?\n",
            "4. Are you experiencing any other issues with your subscription or account?\n",
            "\n",
            "Once I have this information, I'll be happy to look into the matter and see what we can do to get you the refund you're owed.\n",
            "\n",
            "Additionally, I'd like to let you know that our standard refund policy states that we'll process refunds within 5-7 business days of receiving your request. However, in cases of duplicate charges, we'll do our best to expedite the refund process.\n",
            "\n",
            "Let's work together to get this issue resolved for you as soon as possible.\n",
            "\n",
            "Enter your query (or type 'exit'): My python script is throwing an IndexError on line 5.\n",
            "\n",
            "Response:\n",
            " To troubleshoot the issue, I'll need more information about your script. Can you provide the following:\n",
            "\n",
            "1. The exact code causing the error (line 5 and surrounding lines).\n",
            "2. The error message displayed when the IndexError occurs.\n",
            "3. The input or data being used when the error occurs.\n",
            "\n",
            "With this information, I can help you identify the root cause and suggest a solution.\n",
            "\n",
            "Please provide the details, and I'll get started on helping you resolve the issue. \n",
            "\n",
            "If you're unsure about where to start, you can share the entire script or the relevant parts of it.\n",
            "\n",
            "Enter your query (or type 'exit'): exit\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Define Expert Configurations\n",
        "# ==============================\n",
        "\n",
        "MODEL_NAME = \"llama-3.1-8b-instant\"\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"system_prompt\": \"\"\"You are a Technical Support Expert.\n",
        "Be precise, rigorous, and solution-focused.\n",
        "Provide debugging steps, code fixes, and technical explanations.\n",
        "If relevant, show corrected code snippets.\n",
        "Avoid emotional language.\"\"\"\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"system_prompt\": \"\"\"You are a Billing and Subscription Support Expert.\n",
        "Be empathetic and professional.\n",
        "Focus on refund policies, charges, invoices, and subscriptions.\n",
        "Explain financial policies clearly and guide the user step-by-step.\"\"\"\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"system_prompt\": \"\"\"You are a friendly and helpful General Customer Support Assistant.\n",
        "Handle casual conversations and general inquiries politely.\n",
        "Provide clear and concise responses.\"\"\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Router Function (MoE Gate)\n",
        "# ==============================\n",
        "\n",
        "def route_prompt(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Classifies the user input into:\n",
        "    technical, billing, or general\n",
        "    Returns ONLY the category name.\n",
        "    \"\"\"\n",
        "\n",
        "    router_prompt = f\"\"\"\n",
        "Classify the following user request into one of these categories:\n",
        "[technical, billing, general]\n",
        "\n",
        "Return ONLY the category name.\n",
        "\n",
        "User request:\n",
        "\\\"{user_input}\\\"\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=0,  # deterministic routing\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict classification engine.\"},\n",
        "            {\"role\": \"user\", \"content\": router_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    category = response.choices[0].message.content.strip().lower()\n",
        "\n",
        "    # Safety fallback\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    return category\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Orchestrator\n",
        "# ==============================\n",
        "\n",
        "def process_request(user_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Full MoE pipeline:\n",
        "    1. Route to expert\n",
        "    2. Load expert system prompt\n",
        "    3. Generate final response\n",
        "    \"\"\"\n",
        "\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    system_prompt = MODEL_CONFIG[category][\"system_prompt\"]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        temperature=0.7,  # creativity for experts\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Test Runner\n",
        "# ==============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        user_query = input(\"\\nEnter your query (or type 'exit'): \")\n",
        "\n",
        "        if user_query.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        result = process_request(user_query)\n",
        "        print(\"\\nResponse:\\n\", result)\n"
      ]
    }
  ]
}